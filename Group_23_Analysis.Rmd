---
title: "Group 23 Analysis"
author: "Group 23"
output:
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)

library(dplyr)
library(tidyr)
library(ggplot2)
library(knitr)
library(gridExtra)
library(forcats)
library(kableExtra)
library(stringr)
library(skimr)

set.seed(23)

save_plots = FALSE
```
# Introduction 
This project aims to determine which features of items sold by IKEA Saudi Arabia determine whether the items cost more or less than 1000 Saudi Riyals. 
This will be done by carrying out a binary logistic regression on a dataset containing information about items available from the retailer.
The regression parameters will then give us information on which variables affect the probability of the price being above the threshold.
Among those variables that do affect the probability, the relative size of the regression parameters will also allow us to see which variables affect the probability more than others.

# Initial Data Cleaning and Exploration

Having inspected the .csv file, we can see that there are some cleaning steps to be done before the data is usable for modelling.
First, let us look at the first rows of the dataset:

```{r head_dataset}
raw_dataset <- read.csv("dataset23.csv", row.names=1)

raw_dataset <- raw_dataset %>%
  mutate(category=if_else(str_starts(category, 'Caf'), "Cafe furniture", category))

head(raw_dataset, n=5) %>%
  kable(caption = '\\label{tab:head} The features of the first five items in the dataset.', format="latex", booktabs=TRUE) %>%
   kable_styling(font_size = 10, latex_options = "hold_position")
```

The first column, `item_id`, gives a numerical label for each item. This is unlikely to be related to the price of the item, so we should drop it from the dataset. 

## Category
The `category` column is currently presented as a column of strings, but there are a lot of repeated values, as shown in table \ref{tab:categories}

```{r categories_table}
# We will use this data later on
category_counts <- raw_dataset %>%
  group_by(category) %>%
  summarise(number=n()) %>%
  arrange(desc(number))

options(knitr.kable.NA = '')
knitr::kable(
  list(category_counts[1:9,], category_counts[10:18,]),
  caption = '\\label{tab:categories} The distinct categories in the dataset and the number of items in each category, sorted from largest category to smallest.',
  format="latex",
  booktabs = TRUE,
  col.names=c("Category", "Number of Itens")
) %>%
  kable_styling(font_size = 10, latex_options = "hold_position")
```

This means the column should be converted to a factor and treated as a categorical variable in the model. Given that categorical variables create a separate parameter in a model for each unique category, leaving this column in its current form may create a very complex model. We will rely on our model selection procedure to show us which parameters can be dropped from them model.

## Price

This column contains the price of the item in Saudi Riyals, and will be the basis for our target variable. Our aim is to estimate the importance of the other variables in predicting whether an item costs more than 1000 Riyals, i.e. whether the item's entry in column is above or below 1000. The distribution of this column is shown in figure \ref{fig:price_hist}.

```{r price_hist_fig, out.width="90%", out.height="75%", fig.align = "center", fig.pos = "H", fig.cap = "\\label{fig:price_hist} \\textbf{A}: The distribution of prices, measured in Saudi Riyals (SR). Each bin is 250SR wide, and the red line marks 1000SR on the x-axis. \\textbf{B}: The number of items with prices below 1000SR and above 1000SR."}


get_label_x <- function(plt){
  xlim <- ggplot_build(plt)$layout$panel_params[[1]]$x.range[2]
  return(0.925*xlim)
}

get_label_y <- function(plt){
  ylim <- ggplot_build(plt)$layout$panel_params[[1]]$y.range[2]
  return(0.925*ylim)
}


price1 <- ggplot(data=raw_dataset, mapping=aes(x=price)) +
  # center=125 sets the midpoint of the first bin at exactly half the binwidth, so the first bin will start at zero
  geom_histogram(binwidth=250, center=125) +
  # add a vertical line at 1000 as this is the price we will use to create prediction groups
  geom_vline(xintercept = 1000, color="red") +
  xlab("Item Price (SR)") +
  ylab("Number of Items")

if (save_plots){
  ggsave(plot=price1, device="svg", filename="price_hist_A.svg", path="plots")
}

price1 <- price1 + annotate("text", x=get_label_x(price1), y=get_label_y(price1), label="A", size=8)

price_bucket_counts <- raw_dataset %>%
  # create a column saying if the item was over or under 1000SR
  mutate(over_1000=if_else(price < 1000, "Under 1000" ,"Over 1000")) %>%
  group_by(over_1000) %>%
  summarise(number_of_items=n())

price2 <- ggplot(data=price_bucket_counts,
                 # fct_rev() orders the bars in reverse alphabetical order, so we get low price items before high price items
                 mapping=aes(x=fct_rev(over_1000), y=number_of_items)) + 
  geom_col() +
  xlab("Item Price (SR)") +
  ylab("") # Get rid of second y label, the label from the first graph works for both

if (save_plots){
  ggsave(plot=price2, device="svg", filename="price_hist_B.svg", path="plots")
}
price2 <- price2 + annotate("text", x=get_label_x(price2), y=get_label_y(price2), label="B", size=8)

grid.arrange(price1, price2, ncol=2)
g <- arrangeGrob(price1, price2, ncol=2)
```

From these graphs, we can see that the distribution of prices is quite skewed to the right. The first bar of graph A is the largest, so it is most common for items to be priced under 250SR. The bars generally get smaller as the price gets larger, but the distribution has a long tail out to around 9000SR. Graph B shows the number of items below and above 1000SR. It appears that there are around 320 items below 1000SR and around 160 items above 1000SR.

## Sellable Online
The `sellable_online` column is a binary variable indicating whether the item can be purchased via the internet. Table \ref{tab:sellable} shows that this variable is very unbalanced: almost all of the items are available online. This may limit the usefulness of this variable when predicting the price category, but this will become more clear once the model has been fitted.

```{r sellable_online}

raw_dataset %>%
  group_by(sellable_online) %>%
  summarise(number_of_items=n()) %>%
  mutate(sellable_online=if_else(sellable_online, "Sellable Online", "Not Sellable Online")) %>%
  arrange(desc(number_of_items)) %>%
  kable( caption = '\\label{tab:sellable} The number of items available or unavailable online.', format="latex", booktabs=TRUE, col.names=c("", "Number of Items")) %>%
   kable_styling(font_size = 10, latex_options = "hold_position")
```

## Other Colors

The `other_colors` column is another binary variable, taking the value "yes" when the item is available in other colours and "no" when it is not. Table \ref{tab:colours} shows how many items fit into each group. This column is more balanced than `sellable_online`, with about 40% of items available in another colour and 60% unavailable.

```{r colours_table}
raw_dataset %>%
  group_by(other_colors) %>%
  summarise(number_of_items=n()) %>%
  mutate(other_colors=if_else(other_colors=="Yes", "Available in Other Colours", "Not Available in Other Colours")) %>%
  arrange(desc(number_of_items)) %>%
  kable( caption = '\\label{tab:colours} The number of items available or unavailable in other colours.', format="latex", booktabs=TRUE, col.names=c("", "Number of Items")) %>%
   kable_styling(font_size = 10, latex_options = "hold_position")
```

## Depth, Height & Width

These three variables describe the physical dimensions of each item, measured in centimetres. As can be seen from the first row of table \ref{tab:head}, these variables can contain missing values, so we will have to address this before using these variables for modelling. First we can look at the distribution of each variable in figures \ref{fig:dims_1}, \ref{fig:dims_2} and \ref{fig:dims_3}. 

### Depth

From figure \ref{fig:dims_1}, it appears that the most common values are between 20 and 60cm, with the peak being somewhere between 30 and 50cm. The frequency of depths drops off quickly above 60cm, apart from a spike in the 90-100cm bin. There are a few items with depths of greater than 150cm, but most of the distribution occurs below 100cm.

```{r dims_fig_1, out.width="70%",  fig.align = "center", fig.pos = "H", fig.cap = "\\label{fig:dims_1} The distribution of depth measurements in cm. Each bin covers a 10cm range. The blue bars indicate the number of sofas and armchairs in each bin. The grey part of the bar shows the number of all other items."}

raw_dataset %>%
  mutate(category=category == "Sofas & armchairs") %>%
  ggplot(mapping=aes(x=depth, fill=category)) + 
  geom_histogram(binwidth=10, center=5) +
  xlab("Depth (cm)") +
  ylab("Number of items") + 
  scale_fill_manual(values=c("#999999", "#619CFF")) +
  theme(legend.position = "none")

if (save_plots){
  ggsave(device="svg", filename="depth_hist.svg", path="plots")
}
```

```{r depth_spike}
raw_dataset %>%
  filter(!is.na(depth)) %>%
  mutate(
    is_90_100=depth >= 90 & depth <= 100,
    is_sofa=category == "Sofas & armchairs"
    ) %>%
  group_by(is_90_100, is_sofa) %>%
  summarise(count=n()) %>%
  pivot_wider(id_cols=is_90_100, names_from=is_sofa, values_from=count) %>%
  rename(is_sofa="TRUE", is_not_sofa="FALSE") %>%
  mutate(
    total=is_sofa+is_not_sofa,
    sofa_proportion=round(is_sofa/total, 2),
    is_90_100=if_else(is_90_100, "Depth Between 90 & 100cm", "Depth Less Than 90cm or Greater Than 100cm")
    ) %>%
  select(is_90_100, total, sofa_proportion) %>%
  kable( caption = '\\label{tab:sofa_prop} The proportion of items with depth between 90 and 100cm that are sofas, compared to items outside this depth range.', format="latex", booktabs=TRUE, col.names=c("", "Number of Items", "Sofa Proportion")) %>%
   kable_styling(font_size = 10, latex_options = "hold_position")
```
The unusually large number of items with depth between 90cm and 100cm is explained by a large number of sofas having depths in this range, as can be seen from \ref{fig:dims_1}. More precisely, table \ref{tab:sofa_prop} shows that 70% of the items in this depth range are sofas or armchairs, compared to 7% in the rest of the distribution. Items like these may tend to have depths in this range to accommodate cushions, as well as a sitting person.

```{r depth_outliers}
raw_dataset %>%
  filter(!is.na(depth)) %>%
  mutate(
    is_outlier=depth >= 150,
    is_sofa=category == "Sofas & armchairs"
    ) %>%
  group_by(is_outlier, is_sofa) %>%
  summarise(count=n()) %>%
  pivot_wider(id_cols=is_outlier, names_from=is_sofa, values_from=count) %>%
  rename(is_sofa="TRUE", is_not_sofa="FALSE") %>%
  mutate(
    total=is_sofa+is_not_sofa, 
    sofa_proportion=round(is_sofa/total, 2),
    is_outlier=if_else(is_outlier, "Depth Greater Than 150cm", "Depth Less Than 150cm")
    ) %>%
  select(is_outlier, total, sofa_proportion) %>%
  kable( caption = '\\label{tab:sofa_outlier_prop} The proportion of items with depth between 90 and 100cm that are sofas, compared to items outside this depth range.', format="latex", booktabs=TRUE, col.names=c("", "Number of Items", "Sofa Proportion")) %>%
   kable_styling(font_size = 10, latex_options = "hold_position")
```
It can also be seen in figure \ref{fig:dims_1} that the outlying values above 150cm are mostly composed of sofas and armchairs. Table \ref{tab:sofa_outlier_prop} shows the exact proportions of items above and below 150cm in depth that are sofas and armchairs. From these numbers, we can see that items of this category are over represented at depth values over 150cm.


### Height

Figure \ref{fig:dims_2} shows that height is distributed more widely than depth, with some amount of the distribution present from 0 to 250cm. and There are typically 10-30 items in each of the bins between 30 and 110cm, apart from a strong peak between 70 and 90cm. Outside that range, there are typically between 1 and 10 items per bin throughout the variable range.

```{r dims_fig_2, out.width="70%",  fig.align = "center", fig.pos = "H", fig.cap = "\\label{fig:dims_2} The distribution of height measurements in cm. Each bin covers a 10cm range. The blue component of each bar shows the number of items in each bin that are sofas, armchairs, tables, desks or chairs. The yellow part of each bar shows the number of wardrobes, bookcases or shelving units in each bin. The grey part of the bar shows the number of all other items."}

raw_dataset %>%
  mutate(
    is_seating=category %in% c("Sofas & armchairs", "Tables & desks", "Chairs"),
    is_large_storage=category %in% c("Wardrobes", "Bookcases & shelving units"),
    category_tmp=if_else(is_seating, "Seating", "Other"),
    category=if_else(is_large_storage, "Storage", category_tmp)
    ) %>%
  ggplot(mapping=aes(x=height, fill=category)) + 
  geom_histogram(binwidth=10, center=5) +
  xlab("Height (cm)") +
  scale_fill_manual(values=c("#999999", "#619CFF", "#FFCC33")) +
  theme(legend.position = "none")

if (save_plots){
  ggsave(device="svg", filename="height_hist.svg", path="plots")
}
```
```{r height_spike}
raw_dataset %>%
  filter(!is.na(height)) %>%
  mutate(
    is_peak=height >= 70 & height <= 90,
    category=if_else(category %in% c("Sofas & armchairs", "Tables & desks", "Chairs"), category, "Other")
    ) %>%
  mutate(category=str_replace_all(category, " ", "_"), category=str_replace_all(category, "_&(.*)", "")) %>%
  group_by(is_peak, category) %>%
  summarise(count=n()) %>%
  pivot_wider(id_cols=is_peak, names_from=category, values_from=count) %>%
  mutate(
    total= Chairs + Other + Sofas + Tables,
    chair_prop=round(Chairs/total, 2),
    sofa_prop=round(Sofas/total, 2),
    table_prop=round(Tables/total, 2),
    is_peak=if_else(is_peak, "70 - 90", "< 70 or > 90")
  ) %>%
  select(is_peak, total, chair_prop, sofa_prop, table_prop) %>%
  kable(
    caption = '\\label{tab:height_peak_prop} The proportion of items with height between 70 and 90cm that are sofas, armchair, chairs, tables or desks compared to items outside this height range.', 
    format="latex", 
    booktabs=TRUE,
    col.names=c("Height (cm)", "Number of Items", "Chair Proportion", "Sofa Proportion", "Table Proportion")
    )  %>%
   kable_styling(font_size = 10, latex_options = "hold_position")
```
From figure \ref{fig:dims_2}, we can see that a significant proportion of the items between 70 and 90cm in height are in the "Chairs", "Sofa & armchairs" or "Tables & desks" categories, whereas a smaller proportion of items outside this height range appear to fall into these categories. Table \ref{tab:height_peak_prop} shows the proportion of items in the peak of the height distribution that fall into the aforementioned categories, compared to items outside this height range. Within this height range, 15% of items are chairs (compared to 6% elsewhere), 16% are sofas or armchairs (compared to 10% elsewhere) and 31% are tables or desks (compared to 8% elsewhere). This pattern makes sense, as tables need to be of roughly a certain height in order to be useful to most people. Items for sitting on will likely be a similar height to tables, as we typically sit when using a table.

```{r height_large}
raw_dataset %>%
  filter(!is.na(height)) %>%
  mutate(
    is_upper=height > 165,
    category=if_else(category %in% c("Wardrobes", "Bookcases & shelving units"), category, "Other")
    ) %>%
  mutate(category=str_replace_all(category, " ", "_"), category=str_replace_all(category, "_&(.*)", "")) %>%
  group_by(is_upper, category) %>%
  summarise(count=n()) %>%
  pivot_wider(id_cols=is_upper, names_from=category, values_from=count) %>%
  mutate(
    total= Wardrobes + Bookcases + Other,
    wardrobe_prop=round(Wardrobes/total, 2),
    other_prop=round(Other/total, 2),
    bookcase_prop=round(Bookcases/total, 2),
    is_upper=if_else(is_upper, "Height Greater Than 165cm", "Height Less than 165cm")
  ) %>%
  select(is_upper, total, wardrobe_prop, bookcase_prop) %>%
  kable( caption = '\\label{tab:height_upper_prop} The proportion of items over 165cm in height that are wardrobes, bookcases or other items, compared to the proportion for items below 165cm in height.', format="latex", booktabs=TRUE,
    col.names=c("", "Number of Items", "Wardrobe Proportion", "Bookcase Proportion")) %>%
  kable_styling(font_size = 10, latex_options = "hold_position")
```
Figure \ref{fig:dims_2} also shows that the upper part of the height range is dominated by items in the "Wardrobes" and "Bookcases & shelving units" categories. From table \ref{tab:height_upper_prop}, wardrobes and bookcases form a significant proportion of the items over 165cm in height, accounting for 80% of such items in the dataset. They are much less common at lower heights, which is to be expected given that these tend to be used for storing large objects (in the case of wardrobes) or centralising the storage of many small objects (in the case of bookcases).

### Width

The distribution of width measurements is shown in figure \ref{fig:dims_3}. This distribution is somewhat similar to the distribution for depth in figure \ref{fig:dims_1}. There is a large peak roughly between 60 and 80cm, with a long tail to the right. The tail is heavier here than for depth, with items appearing all the way out to 360cm.
```{r dims_fig_3, out.width="70%",  fig.align = "center", fig.pos = "H", fig.cap = "\\label{fig:dims_3}The distribution of width measurements in cm. Each bin covers a 20cm range. The yellow bars represent the number of chairs in each bin and the blue bars represent the number of tables or desks in each bin. The grey bars represent the number of all other items."}

raw_dataset %>% 
  mutate(
    is_chair=category =="Chairs",
    is_table = category == "Tables & desks",
    category_tmp=if_else(is_chair, "Chair", "Other"),
    category=if_else(is_table, "Table", category_tmp),
    category=factor(category, levels=c("Other", "Chair", "Table"))
    ) %>%
  ggplot(mapping=aes(x=width, fill=category)) + 
  geom_histogram(binwidth=20, center=10) +
  xlab("Width (cm)") +
  scale_fill_manual(values=c("#999999","#FFCC33",  "#619CFF")) +
  theme(legend.position = "none")

if (save_plots){
  ggsave(device="svg", filename="width_hist.svg", path="plots")
}
```
The distribution of width (shown in figure \ref{fig:dims_3}) appears to be more regular than that of depth or height. however, items are not uniformly represented throughout the distribution, as items from the "Chairs" and "Tables and desks" categories are present close to the peak of the distribution but absent in the tails.

```{r width_peak}
raw_dataset %>%
  filter(!is.na(width)) %>%
  mutate(
    is_peak=width >= 40 & width <= 80,
    category=if_else(category %in% c("Chairs", "Tables & desks"), category, "Other")
    ) %>%
  mutate(category=str_replace_all(category, " ", "_"), category=str_replace_all(category, "_&(.*)", "")) %>%
  group_by(is_peak, category) %>%
  summarise(count=n()) %>%
  pivot_wider(id_cols=is_peak, names_from=category, values_from=count) %>%
  mutate(
    total= Chairs + Tables + Other,
    chair_prop=round(Chairs/total, 2),
    table_prop=round(Tables/total, 2),
    is_peak=if_else(is_peak, "40 - 80", "< 40 or > 80")
  ) %>%
  select(is_peak, total, chair_prop, table_prop) %>%
  kable( caption = '\\label{tab:width_peak_prop} The proportion of items between 40 and 80cm in width that are chairs or tables and desks compared to these proportions for items outside this width range.', format="latex", booktabs=TRUE,
    col.names=c("Width (cm)", "Number of Items", "Chair Proportion", "Table Proportion")) %>%
  kable_styling(font_size = 10, latex_options = "hold_position")
```
From table \ref{tab:width_peak_prop}, it can be seen that chairs and tables form a larger proportion of the items in the peak of the width distribution (between 40 and 80cm) than outside this range.

These distributions may have more structure hidden in them, as they include a range of items of many different categories. It is reasonable to expect that the dimensions of items in different categories would be distributed differently. For instance, we would expect wardrobes to typically be taller than chairs. We can examine the distributions of these variables for some of the larger categories listed in table \ref{tab:categories}.

### Dimensions of Different Categories
The distributions of depth, height and width for each category are shown in figures \ref{fig:depth_by_category}, \ref{fig:height_by_category} and \ref{fig:width_by_category}, respectively. The top plots show the 8 largest categories and the bottom plots show the rest. 


```{r depth_by_category_fig, fig.height=4, fig.align = "center", fig.cap = "\\label{fig:depth_by_category} Boxplots of the depth (in cm) of items in each category."}
cats <- category_counts$category[1:8]

depth1 <- raw_dataset %>%
  filter(category %in% cats) %>%
  mutate(category=str_wrap(category, 10)) %>%
  ggplot(mapping=aes(x=category, y=depth)) +
  geom_boxplot() +
  xlab("") +
  ylab("Depth (cm)")

depth2 <- raw_dataset %>%
  filter(!(category %in% cats)) %>%
  mutate(category=str_wrap(category, 10)) %>%
  ggplot(mapping=aes(x=category, y=depth)) +
  geom_boxplot() +
  xlab("Category") +
  ylab("Depth (cm)")

if (save_plots){ 
  ggsave(depth1, device="svg", filename="depth_box_top.svg", path="plots")
  ggsave(depth1, device="svg", filename="depth_box_bottom.svg", path="plots")
}
grid.arrange(depth1, depth2, ncol=1)
```
From the upper plot in figure \ref{fig:depth_by_category} we can see that the median depths for the more common categories are often around 50cm. The clear exceptions to this are the "Beds", "Outdoor Furniture" and "Sofas & Armchairs" categories. For the less common categories, the median depth is also typically close to 50cm, except for "Nursery Furniture" and "Trolleys". These categories have only a small number of items in each, so the distributions are likely to be noisier than for more numerous categories. There is also some difference in the range of these distributions, particularly for "Beds". This may be due to double and single beds both being included in this category.

```{r height_by_category_fig, fig.height=4, fig.align = "center", fig.pos = "H", fig.cap = "\\label{fig:height_by_category} Boxplots of the height (in cm) of items in each category."}
height1 <- raw_dataset %>%
  filter(category %in% cats) %>%
  mutate(category=str_wrap(category, 10)) %>%
  ggplot(mapping=aes(x=category, y=height)) +
  geom_boxplot() +
  xlab("") +
  ylab("Height (cm)")

height2 <- raw_dataset %>%
  filter(!(category %in% cats)) %>%
  mutate(category=str_wrap(category, 10)) %>%
  ggplot(mapping=aes(x=category, y=height)) +
  geom_boxplot() +
  xlab("Category") +
  ylab("Height (cm)")

if (save_plots){
  ggsave(height1, device="svg", filename="height_box_top.svg", path="plots")
  ggsave(height2, device="svg", filename="height_box_bottom.svg", path="plots")
}
grid.arrange(height1, height2, ncol=1)
```
Figure \ref{fig:height_by_category} shows the boxplots of height for each category. In the upper plot, we can see that the median height for several of the categories is approximately 75cm, with the exception of "Bookcases & shelving units", "Cabinets & cupboards" & "Wardrobes". Interestingly, the median height of wardrobes is very close to the maximum height for this category, indicating that there are many items with the same or similar height. In the lower plot, the median heights are typically somewhat similar, between 75 and 100cm with the exception of "Room dividers", "Sideboards, buffets & console tables" (with medians over 100cm) and "TV & media furniture" with median height around 50cm.

```{r width_by_category_fig, fig.height=4, fig.align = "center", fig.pos = "H", fig.cap = "\\label{fig:width_by_category} Boxplots of the width (in cm) of items in each category."}
width1 <- raw_dataset %>%
  filter(category %in% cats) %>%
  mutate(category=str_wrap(category, 10)) %>%
  ggplot(mapping=aes(x=category, y=width)) +
  geom_boxplot() +
  xlab("") +
  ylab("Width (cm)")

width2 <- raw_dataset %>%
  filter(!(category %in% cats)) %>%
  mutate(category=str_wrap(category, 10)) %>%
  ggplot(mapping=aes(x=category, y=width)) +
  geom_boxplot() +
  xlab("Category") +
  ylab("Width (cm)")

if (save_plots){
  ggsave(width1, device="svg", filename="width_box_top.svg", path="plots")
  ggsave(width2, device="svg", filename="width_box_bottom.svg", path="plots")
  
}

grid.arrange(width1, width2, ncol=1)
```
Lastly, figure \ref{fig:width_by_category} shows the boxplots of width for each category. In the upper plot, the medians range from approximately 50cm ("Chairs" and "Outdoor furniture") to much larger values: "Beds" and "Wardrobes" have medians of around 150cm and "Sofas & armchairs" has a median of over 200cm. The ranges of width values for the categories in this plot are often quite wide, for instance "Sofas & armchairs" ranges from below 50cm to over 300cm. For the lower plot, the medians appear a little more consistent, typically around 50cm, although "Chests of drawers & drawer units", "Room dividers" and "Sideboards, buffets & console tables" have noticeably larger medians. 


## Missing Data

```{r missing_data}
null_skim <- skim_with(base = sfl(n_missing=n_missing, complete_rate=complete_rate), character=sfl(), numeric=sfl(), logical=sfl(), append=FALSE)

raw_dataset %>% 
  null_skim() %>%
  select(-skim_type) %>%
  kable( caption = '\\label{tab:nulls} The number of missing values in each column and the proportion of each column that is not missing.', format="latex", booktabs=TRUE, col.names=c("Variable Name", "Number of Missing Values", "Proportion of Non-Missing Values")) %>%
  kable_styling(font_size = 10, latex_options = "hold_position")

drop_proportion <- (raw_dataset %>%
  filter(if_any(c("depth", "height", "width"), is.na)) %>%
  nrow()) / nrow(raw_dataset)
```
Some of the items in the dataset are missing values for some variables, as can be seen from the first row of table \ref{tab:head}. Table \ref{tab:nulls} shows the number of missing values in each column, along with the proportion of items that are not missing a value in that column. The only variables with missing information are the ones describing the dimensions of the item: depth, height and width. These missing values must be handled somehow if the data is to be used for modelling. The simplest way to treat this data would be to drop all rows which are missing one or more values. However, it can be seen from \ref{tab:nulls} that only 60.2% of rows are not missing their depth value. This means that dropping rows with missing values would remove at least 39.8% of the dataset. In fact, taking all three dimension variables into account, this cleaning strategy would remove `r round(100 * drop_proportion, 1)`% of the rows in the dataset. This seems like too much data to lose, so we must impute the missing values somehow. The distributions of these variables have some slightly irregular features and outliers, so mean imputation may be inappropriate. The median may be a more robust approach, although a global median for each variable may also be inappropriate as the distribution of each variable can differ strongly between item categories, as shown in figures \ref{fig:depth_by_category}, \ref{fig:height_by_category} and \ref{fig:width_by_category}. Therefore, we can try cleaning these columns by assigning the median of the relevant item category in place of missing values.

### Multiple Missing Values
```{r all_missing_data}
all_missing_proportion <- (raw_dataset %>%
   filter(if_all(c("depth", "height", "width"), is.na)) %>%
   nrow()) / nrow(raw_dataset)
```
In some cases, all 3 dimension variables are missing from an item. This occurs in `r round(all_missing_proportion, 1)`% of rows. As this is a small proportion of the overall dataset and imputing all 3 dimensions of the item would likely lead to a poor approximation of the true values, we should drop these rows from the dataset we use for modelling.

## Cleaning the Data
We are now in a position to prepare the dataset for modelling. The processing steps to be done are:

* Discard the `item_id` column
* Convert `category`, `sellable_online` and `other_color` to be factors
* Convert the `price` column into a binary target variable based on whether it is greater than 1000SR
* Drop any rows where all 3 of `depth`, `height` and `width` are missing
* Replace any remaining missing values of `depth`, `height` and `width` with the median value for their category.

Having applied these steps, we can see the features of the cleaned data. Comparing tables \ref{tab:head} and \ref{tab:cleaned} shows that the transformations appear to have worked: the price is now a binary variable matching what we'd expect from the value in table \ref{tab:head} and the missing value for `depth` in the first row has been replaced, while the categorical variables appear unchanged apart from being converted into factors in the background. 
```{r apply_cleaning_steps}
cleaned_dataset <- raw_dataset %>%
  # filter out rows missing all 3 columns
  filter(!if_all(c("depth", "height", "width"), is.na)) %>% 
  select(-item_id) %>% #drop the item id column
  mutate( # most of the changes are simple vectorised conversions
    category=as.factor(category), 
    sellable_online=as.factor(sellable_online), 
    other_colors=as.factor(other_colors),
    price=factor(if_else(price >= 1000, 1, 0), levels=c(0, 1), labels=c("Below 1000SR", "Above 1000SR"))
    )

# replacing missing values will be more complicated
# there may be a cleaner way to do this
for (cat in category_counts$category){ #loop through each category in the dataset
  
  cat_filter <- cleaned_dataset$category == cat  # find all items of this category
  
  for (i in 5:7){ # for each dimension column (columns 5, 6 and 7)
    
    # find all items with NA in this column
    na_filter <- is.na(cleaned_dataset[, i])
    
    # replace the values matching both filters with the median for this category
    cleaned_dataset[cat_filter & na_filter, i] <- median(cleaned_dataset[cat_filter, i], 
                                                         na.rm=TRUE)
  }
}

head(cleaned_dataset, n=5) %>% 
  kable(caption = '\\label{tab:cleaned} The features of the first five items in the dataset after the cleaning steps have been applied.', format="latex", booktabs=TRUE) %>%
   kable_styling(font_size = 10, latex_options = "hold_position")
```
# Modelling

We can now begin considering our model. The first step here is to examine the relationship between each explanatory variable and the response variable.

## Relationship Between Variables and Response

The data is now ready to be used for modelling. Before fitting the model, we can examine the relationship between the covariates and the response variable.

### Category

First, we can see the proportion of items in each category that are above or below 1000SR, shown in figure \ref{fig:cat_y_dist}. There is a lot of variation between the different categories, even between categories with many items. For instance, Sofas & armchairs has the greatest proportion of items above 1000SR (around 75%), whereas for Chairs the proportion is roughly 25%. From this, we may expect that category will be a useful predictor of whether an item has price above 1000SR.

```{r cat_y_dist_fig,  fig.align = "center", fig.pos = "H", fig.cap = "\\label{fig:cat_y_dist} The proportion of items in each category with price below or above 1000SR."}
cleaned_dataset %>% ggplot(mapping=aes(x=str_trunc(as.character(category), 9, ell="..."), fill=price)) +
    geom_bar(position="fill") +
  theme(axis.text.x = element_text(angle = 90, vjust=0.4)) + 
  xlab("Category") + 
  ylab("Proportion")

if (save_plots){
  ggsave(device="svg", filename="category_y_dist.svg", path="plots")
}
```

### Sellable Online
As figure \ref{fig:sell_y_dist} shows, all items which are not available online have price below 1000SR. This deviation from the population price distribution is not surprising, as there are only 5 items in this group (see table \ref{tab:sellable}). As a result, it seems unlikely that this variable will be useful in predicting the response variable.

```{r sell_y_dist_fig,  fig.align = "center", fig.pos = "H", fig.cap = "\\label{fig:sell_y_dist} The proportion of items with price below or above 1000SR, grouped by whether they are sellable online or not."}
cleaned_dataset %>% 
  mutate(sellable_online = if_else(as.logical(sellable_online), "Sellable Online", "Not Sellable Online")) %>%
  ggplot(mapping=aes(x=sellable_online, fill=price)) +
  geom_bar(position="fill") +
  xlab("") + 
  ylab("Proportion")

if (save_plots){
  ggsave(device="svg", filename="sellable_online_y_dist.svg", path="plots")
}
```

### Other Colors

Figure \ref{fig:col_y_dist} shows the distribution of response variable values for items grouped by whether they are available in other colors or not. It appears that items available in multiple colors are more likely to have prices above 1000SR (about 45%) than those available in just one color (closer to 25%). Based on this, this variable may be a moderately strong predictor of whether the item's price is above the threshold.
```{r col_y_dist_fig,  out.width="70%", fig.align = "center", fig.pos = "H", fig.cap = "\\label{fig:col_y_dist} The proportion of items with price below or above 1000SR, grouped by whether they are available in other colors or not."}
cleaned_dataset %>%
  mutate(other_colors=if_else(other_colors=="Yes", " Available in Other Colors", "Not Available in Other Colors")) %>%
  ggplot(mapping=aes(x=other_colors, fill=price)) +
  geom_bar(position="fill") +
  xlab("") + 
  ylab("Proportion")

if (save_plots){
  ggsave(device="svg", filename="other_colors_y_dist.svg", path="plots")
}
```

### Depth
For each value of the response variable, figure \ref{fig:depth_y_dist} shows a boxplot of the depth distribution. The upper quartile for items in the lower price bracket is just over 50cm, whereas the lower quartile of the more expensive items is just below 50cm and the upper quartile is near 100cm. This suggests that an item with a large depth value will have a price above 1000SR.
```{r depth_y_dist_fig,  out.width="70%", fig.align = "center", fig.pos = "H", fig.cap = "\\label{fig:depth_y_dist} Boxplots of depth for items with price below or above 1000SR."}
ggplot(cleaned_dataset, aes(x = price, y = depth, fill = price)) +
  geom_boxplot() +
  labs(x = "Price", y = "Depth (cm)")+ 
  theme(legend.position = "none")

if (save_plots){
  ggsave(device="svg", filename="depth_y_dist.svg", path="plots")
}
```

### Height
Similarly, we can plot the height distributions for the two values of the response variable. This is done in figure \ref{fig:height_y_dist}. Again, a greater height appears to indicate a greater probability of an item being in the higher price range. However, the distinction between the groups is less clear here, with the upper quartile of the "Below" group entirely overlapping the lower quartile of the "Above" group and outliers from the "Below" group extending all the way to the top of the range of the "Above" group. This variable may be a useful indicator of the response variable, but perhaps to a lesser degree than depth.

```{r height_y_dist_fig,  out.width="70%", fig.align = "center", fig.pos = "H", fig.cap = "\\label{fig:height_y_dist} Boxplots of height for items with price below or above 1000SR."}
ggplot(cleaned_dataset, aes(x = price, y = height, fill = price)) +
  geom_boxplot() +
  labs(x = "Price", y = "Height")+ 
  theme(legend.position = "none")

if (save_plots){
  ggsave(device="svg", filename="height_y_dist.svg", path="plots")
}
```

### Width

Lastly, we plot the distribution of width for the two values of the response variable in figure \ref{fig:width_y_dist}. This shows a similar pattern to figures \ref{fig:depth_y_dist} and \ref{fig:height_y_dist}: The lower priced items generally have smaller width values. The difference between the groups is more distinct than for height, but there are still outliers from the lower priced group extending through much of the higher priced group's range. This variable may be a fairly strong predictor of the response: perhaps stronger than height but weaker than depth.

```{r width_y_dist_fig,  out.width="70%", fig.align = "center", fig.pos = "H", fig.cap = "\\label{fig:width_y_dist} Boxplots of width for items with price below or above 1000SR."}
ggplot(cleaned_dataset, aes(x = price, y = width, fill = price)) +
  geom_boxplot() +
  labs(x = "Price", y = "Width")+ 
  theme(legend.position = "none")

if (save_plots){
  ggsave(device="svg", filename="width_y_dist.svg", path="plots")
}
```

## Model Selection

At last, we can fit some models to investigate our question of interest: determining which variables influence whether an item will cost more than 1000SR. To do this we will fit a binary GLM with the price column as the target variable. The regression coefficients will then give the change in log-odds associated with a unit change in the corresponding covariate. Comparing the coefficients, then, will show us which variables are most important in determining whether an item costs more than 1000SR. The first model to fit will be a model incorporating all of the available covariates.

### Full Model

```{r set_strings}
# This is a silly workaround, but the latex equation won't knit without it
s_online <- "sellable_online"
```
This model is of the form:
$$\log\left(\frac{p_i}{1-p_i}\right) = \beta_0 + \sum_{j}^{16}\beta_j\mathbb{I}_{j}(x_{i}) + \beta_{17}\mathbb{I}_{sellable}(x_i) + \beta_{18}\mathbb{I}_{colours}(x_i) + \beta_{19}x_{i,depth} + \beta_{20}x_{i,height} + \beta_{21}x_{i,width}$$
where:

* $p_i$ is the probability of the i<sup>th</sup> item having price above 1000SR
* $\beta_0$ is the intercept term
* $\beta_1, \beta_2, ..., \beta_{21}$ are the regression parameters
* $\mathbb{I}_1(), \mathbb{I}_2(), ..., \mathbb{I}_{16}()$ are indicator functions evaluating to 1 if the i<sup>th</sup> item is in the corresponding category. For the 17 categories, 16 indicators are required as the baseline category is represented by all indicator functions returning zero.
* $\mathbb{I}_{sellable}()$ is an indicator function returning 1 if the i<sup>th</sup> item is sellable online and 0 otherwise
* $\mathbb{I}_{colours}()$ is an indicator function returning 1 if the i<sup>th</sup> item is available in other colors and 0 otherwise
* $x_{i, depth}, x_{i, height}, x_{i, width}$ are the depth, width and height of the i<sup>th</sup> item in centimetres.

Table \ref{tab:full_model} shows the fitted parameter estimates for this model. We can see that the confidence intervals parameters associated with each of the different category values are all very wide and include zero. This indicates that, when controlling for the other variables in the model, the category has no statistically significant effect on the propability of an item costing more than 1000SR. Given the differences seen in figure \ref{fig:cat_y_dist}, it is surprising that none of the category parameters are significant, but it may be the case that the differences between categories are explained by other variables.

As category contributes a lot of complexity to the model and no significant parameters, we shall drop it and re-fit the model. 

```{r full_model_table, warning=F, message=F}
# Fit a binary logistic regression model
model1 <- glm(price ~ category + sellable_online + other_colors + depth + height + width,
             data = cleaned_dataset, family = binomial(link = "logit"))
coeffs <- summary(model1)$coefficients[, 1]

knitr::kable(
  round(cbind(coeffs, confint.default(model1)), 3),
  format="latex",
  booktabs=TRUE,
  caption = '\\label{tab:full_model} The parameter estimates and associated confidence intervals from the first model.',
  col.names=c("Parameter Estimate", "95% CI Lower Bound", "95% CI Upper Bound")
  ) %>%
  kable_styling(font_size = 10)
```

### Model Without Category

The model fitted here contains all the same terms as the full model, except the terms involving $\beta_1, \beta_2, ..., \beta_{16}$. The parameter estimates are shown in table \ref{tab:mid_model}. The confidence intervals for sellable_online and other_colors, while smaller than they were in the first model, both include zero. Therefore these variables still do not have a significant effect on the log-odds of an item costing more than 1000SR. We can see that depth, width and height all have confidence intervals that do not include zero. We can now fit a model with just these three variables.

```{r mid_model_table, warning=F, message=F}
# Fit a binary logistic regression model
model2 <- glm(price ~ sellable_online + other_colors + depth + height + width,
             data = cleaned_dataset, family = binomial(link = "logit"))
coeffs <- summary(model2)$coefficients[, 1]

knitr::kable(
  round(cbind(coeffs, confint.default(model2)), 3),
  format="latex",
  booktabs=TRUE,
  caption = '\\label{tab:mid_model} The parameter estimates and associated confidence intervals from the second model.',
  col.names=c("Parameter Estimate", "95% CI Lower Bound", "95% CI Upper Bound")
  ) %>%
  kable_styling(font_size = 10)
```

### Model with Only Numeric Variables

```{r size_model_table, warning=F, message=F}
model3 <- glm(price~height+width+depth, cleaned_dataset, family = "binomial")
coeffs <- summary(model3)$coefficients[, 1]

knitr::kable(
  round(cbind(coeffs, confint.default(model3)), 3),
  format="latex",
  booktabs=TRUE,
  caption = '\\label{tab:size_model} The parameter estimates and associated confidence intervals from the third model.',
  col.names=c("Parameter Estimate", "95% CI Lower Bound", "95% CI Upper Bound")
  ) %>%
  kable_styling(font_size = 10)
```

The final model fitted here is one including only the depth, width and height covariates. These all had significant parameters in the previous model, so we expect them to still be significant now the other variables have been removed. From table \ref{tab:size_model}, we can see that all parameters in this model (including the intercept) have confidence intervals that do not include zero, and are therefore significant at the $\alpha = 0.05$ level.

### Model AIC Comparison
The performance of the models can be compared by using the Akaike Information Criterion (AIC), a metric that rewards better fitting models but penalises models with many parameters. A lower value of AIC indicates a better model. Of the three models fitted here, the first (with all parameters) had the best AIC value, `r round(model1$aic, 2)`. The next best was the third model, with only depth, width and height as explanatory variables, with an AIC value of `r round(model3$aic, 2)`. The second model (excluding only the category variable) had the worst AIC value, `r round(model2$aic, 2)`. This is somewhat surprising, as all the extra parameters in the first model were not significant, and so might be expected to contribute little to the fit of the model while being penalised by the AIC calculation. The third model outperforming the second model is more expected, as it is a smaller model that ignores some insignificant parameters. Despite it having the best AIC value, we decide not to use the full model as it does not help answer the research question; the category parameters are insignificant and may obscure the effect of other covariates.


### Parameter Comparison
Comparing the parameters, we can see that depth has the largest estimated parameter, with a value of `r round(coeffs["depth"], 3)`. This means that for every extra centimetre in depth, we expect the log-odds of the item costing over 1000SR to increase by `r round(coeffs["depth"], 3)`. This is equivalent to mutliplying the odds of this outcome by `r round(exp(coeffs["depth"]), 3)`. The next largest parameter is for width, which gives the expected log-odds increase per centimetre of width as `r round(coeffs["width"], 3)`, or an odds multiplier of `r round(exp(coeffs["width"]), 3)`. The smallest parameter of the three is height, giving a log-odds increase of `r round(coeffs["height"], 3)` (odds multiplier of `r round(exp(coeffs["height"]), 3)`) per centimetre.

The fact that these are the only variables that seem to have an effect on whether the price of the item is greater than 1000SR makes some sense, as the dimensions of the item determine roughly how much material went into making it and how costly it is to transport. The same amount of raw materials would plausibly cost the same regardless of whether you were building a bookcase or a bed. The relative sizes of the parameters is also somewhat expected, given the distributions seen in figures \ref{fig:depth_y_dist}, \ref{fig:height_y_dist} and \ref{fig:width_y_dist}, as the depth distribution was the most clearly separate between the price groups, followed by the width distribution and then the height distribution.


# Conclusions
Fitting binary GLMs to the data and iteratively removing insignificant parameters indicates that the only variables influencing whether an item costs more than 1000 Saudi Riyals, are the depth, width and height of the item. Depth influenced the probability most, followed by width and then height. The category of item did not significantly affect the probability, despite different categories having quite different proportions of items in each price bracket. This may be due to the category correlating with the item size, but this modelling work could be extended to investigate this further. For instance, instead of including a parameter for each category in the model, the category variable could be converted into dummy variables and these variables could be removed one at a time during model selection, rather than all at once. This may lead to some informative categories being retained. As the results here indicate that the item size is the determining factor in whether its price is above 1000SR, a further extension to the work could be to multiply depth, width and height together to create a "volume" variable and fit a model using this covariate. This would indicate whether it is just overall "size" that determines price, and not the individual dimensions separately.